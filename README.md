ðŸ‘‹ Hi, Iâ€™m Arnav

Iâ€™m focused on **AI systems engineering**, with an emphasis on understanding how
LLM-based systems *actually behave* under real constraints.

My current work centers on:

- Retrieval-Augmented Generation (RAG)
- Agent architectures (planning, tools, memory)
- Evaluation, observability, and failure modes in LLM systems

Iâ€™m learning by building **small, inspectable systems** and publishing them openly.
Each repository is designed to isolate one idea, decision, or failure mode â€”
starting from minimal baselines and adding complexity only when justified.

This is not about demos or frameworks.

Most repositories here are:
- controlled experiments
- system baselines
- evaluation harnesses
- learning artifacts with explicit assumptions and limits

The goal is long-term:  
to develop sound intuitions about system design, tradeoffs, and failure â€”
and to turn research ideas into working, testable code.

If youâ€™re interested in **how modern AI systems break â€” and how to reason about them**,
this profile is a public record of that process.
